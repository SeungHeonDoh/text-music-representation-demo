<!DOCTYPE html>
<html>
    
    <head>
        <meta charSet="UTF-8" />
        <title>SeungHeon Doh | MIR, ML/DL Researcher</title>
        <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>ðŸŽ¹</text></svg>"></link>
        <meta httpEquiv="x-ua-compatible" content="ie=edge" />
        <meta name="viewport" content="width=device-width, initial-scale=1" />
        <meta name="description" content="" />
        <meta name="keywords" content="" />
        <meta name="robots" content="index, follow, noodp" />
        <meta name="googlebot" content="index, follow" />
        <meta name="google" content="notranslate" />
        <meta name="format-detection" content="telephone=no" />
        <title>SeungHeonDoh</title>
    </head>
    <style>
        header{        
            padding-top: 1.91rem;
        }
        header a{
            color: gray !important;
            text-decoration: none;
        }
        h1, h2, h3, h4, h5, h6 {
            font-family: "helvetica";
            margin-bottom: 1.01rem;
        }

        p{
            margin-bottom: 10px;
            line-height: 1.7;
        }
        small{
            font-size: 0.8rem;
        }
        b{
            color: blue;
        }
        h1 {
            font-size: 5rem;
            line-height: 1.15;
            }

        h2 {
            font-size: 4rem;
            line-height: 1.11;
        }

        h3 {
            font-size: 2rem;
            line-height: 1.74;
        }

        h4 {
            font-size: 1.4rem;
            line-height: 1.39;
        }

        h5 {
            font-size: 1.2rem;
            line-height: 1.56;
            margin-bottom: 0.5em;
        }

        h1, h2, h3, h4, h5, h6 {
            line-height: 1.56;
            margin-bottom: 1.01rem;
        }

        .main table {
            display: inline-table;
        }
        table {
            table-layout:fixed;
            width: 100%;
            overflow: hidden;
        }
        #player{
            width: 100%;
        }
        img, svg {
            max-width: 100%;
            height: auto;
        }

        .blog_contents{
            margin-bottom: 1rem;
        }

        .footer{
            height: 50px;
            background-color: white;
        }

        .wrapper {
            max-width: 1920px;
            margin: auto;
            padding-left: 20rem;
            padding-right: 20rem;
            }
        @media(max-width: 1700px){
            .wrapper {
                padding-left: 8rem;
                padding-right: 8rem;
            }
            }

        @media(max-width: 1199px){
            .wrapper {
            padding-left: 5rem;
            padding-right: 5rem;
            }
        }

        @media(max-width: 575px){
            .wrapper {
            padding-left: 1.25rem;
            padding-right: 1.25rem;
            }
        }
    </style>

    <body style="background-color: #f8f8f8;">
        <header id="header" class="site-header">
            <div class="wrapper">
                <a 
                    title="nav"
                    class="btn btn-link transform-scale-h border-0 p-0"
                    href="https://seungheondoh.github.io/#/">Home</a>
            </div>
        </header>
    
        <main id="main" class="site-main">
            <div class="wrapper">
                <h3>Toward Universal Text-to-Music Retrieval</h3>
                    <pre><code>Toward unified text-music representation learning, ICASSP 2023 (submitted) - SeungHeon Doh, Minz Won, Keunwoo Choi, Juhan Nam
                    </code></pre>
            <p>This project maps <strong>text {tag, sentence}</strong> and <strong>music</strong> to the same embedding space.
                For the details of the methodology for building the dataset, please refer to our paper.</p>
            <ul>
                <!-- <li><a href="">Paper on Arxiv</a>(will be updated)</li> -->
                <li><a href="https://arxiv.org/abs/2211.14558">Paper on Arxiv</a></li>
                <li><a href="https://github.com/seungheondoh/music-text-representation">Implementation Code</a></li>
                <li><a href="https://github.com/seungheondoh/msd-subsets">Dataset Code</a></li>
                <li><a href="https://zenodo.org/record/7322135">Pre-trained model on Zenodo</a></li>
                <li><a href="https://github.com/seungheondoh/msu-benchmark">Downstream benchmark</a></li>
            </ul>

            <h4>Motivation</h4>
            <p>
                Generalizable text-based music retrieval systems need to cover both tag-based and sentence-based queries. For example, ordinary listeners use simple tag-based queries to explore music libraries. Music creators may use sentence-based queries to retrieve more specific types of music. Content creators use content descriptions (less musical and often include unseen tags) to retrieve suitable music that matches their media content, such as photos and videos. 
            </p>
            <img class="blog_contents" src="assets/img/main.png" alt="text_to_music"/> 
            <p>
            This paper introduces effective design choices of universal multi-modal representation learning for text-to-music retrieval. 
            Our reusable insights are summarized as follows:
            </p>
            <ul>
                <li>For tags and sentence query, use stochastic text representations. </li>
                <li>For robust to unseen query, use contrastive loss. </a></li>
                <li>For sentence query (Specifically), use BERT text encoder. </a></li>
            </ul>
            
            <h4>Demo</h4>
                <p> The music pool in the demo was a test-set of the ECALS dataset. All samples were not used in the training phase. For space reasons, we compare tag, sentence and stochastic representations using the contrastive framework.
                </p>
                <p><strong>The key message of the demo is:</strong> the stochastic model shows robust search performance for tag, sentence, and unseen queries. Contrary to this, the sentence model has poor search performance for low popular specific instruments, such as banjo. The tag model is difficult to search for combinations in various semantics such as fusion jazz with synth, bass, drums, and saxophone.</p>
                <hr/>

                <p><b>fusion jazz with synth, bass, drums, saxophone</b> (Sentence Query)</p>
                <table>
                    <tr>
                        <th> Model </th>
                        <th> Similar Music 1 </th>
                        <th> Similar Music 2 </th>
                        <th> Similar Music 3 </th>
                    </tr>
                    <tr> 
                        <th> Contrastive-BERT-Tag </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/tag/mq.mp3" type="audio/mpeg"></audio> </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/tag/mq (1).mp3" type="audio/mpeg"></audio> </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/tag/mq (2).mp3" type="audio/mpeg"></audio> </th>
                    </tr>
                    <tr> 
                        <th> </th>
                        <th> <small>hard bop, jazz, jazz instrument, strong, lively, saxophone jazz, nervous jittery, swinging</small> </th>
                        <th> <small>exuberant, swing, rollicking, amiable good natured, jazz, piano blues, big band, hanging out, joyous, tgif, late night, playful, ..</small> </th>
                        <th> <small>energetic, sophisticated, day driving, exuberant, searching, bright, bravado, intense, passionate, rollicking, confident, hard bop, ...</small> </th>
                    </tr>
                    <tr> 
                        <th> Contrastive-BERT-Sentence </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/caption/mq.mp3" type="audio/mpeg"></audio> </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/caption/mq (1).mp3" type="audio/mpeg"></audio> </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/caption/mq (2).mp3" type="audio/mpeg"></audio> </th>
                    </tr>
                    <tr> 
                        <th> </th>
                        <th> <small>sophisticated, refined, soul, pop rock, amiable good natured, laid back mellow, jazz, contemporary pop rock, chill, synth pop, dance rock, punk new wave, new wave, ...</small> </th>
                        <th> <small>sentimental, amiable good natured, confident, sweet, in love, earnest, sensual, lively, romantic evening, funk, warm, rnb, heartache, intimate, summery, ...</small> </th>
                        <th> <small>smooth jazz, jazz, jazz instrument, mainstream jazz, saxophone jazz, contemporary jazz, crossover jazz</small> </th>
                    </tr>
                    <tr> 
                        <th> Contrastive-BERT-Stochastic </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/stochastic/mq.mp3" type="audio/mpeg"></audio> </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/stochastic/mq (1).mp3" type="audio/mpeg"></audio> </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/stochastic/mq (2).mp3" type="audio/mpeg"></audio> </th>
                    </tr>
                    <tr> 
                        <th> </th>
                        <th> <small>energetic, exuberant, urban, rollicking, confident, gutsy, sweet, happy, sexual, brash, funk, warm, rousing, joyous, rnb, quiet storm, celebratory, playful, partying, cheerful, ...</small> </th>
                        <th> <small>80s</small> </th>
                        <th> <small>energetic, soul, pop rock, passionate, rollicking, amiable good natured, confident, laid back mellow, latin rock, freewheeling, funk, rnb, summer, comfort, 70s, celebratory, ...</small> </th>
                    </tr>
                </table>
                <hr/>

                <p><b>Banjo</b> (Tag Query)</p>
                <table>
                    <tr>
                        <th> Model </th>
                        <th> Similar Music 1 </th>
                        <th> Similar Music 2 </th>
                        <th> Similar Music 3 </th>
                    </tr>
                    <tr> 
                        <th> Contrastive-BERT-Tag </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/tag/banjo.mp3" type="audio/mpeg"></audio> </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/tag/banjo (1).mp3" type="audio/mpeg"></audio> </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/tag/banjo (2).mp3" type="audio/mpeg"></audio> </th>
                    </tr>
                    <tr> 
                        <th> </th>
                        <th> <small>pop rock, alternative, folk, rock</small> </th>
                        <th> <small>exuberant, passionate, amiable good natured, new orleans, happy, romantic, rousing, joyous, celebratory, playful, rambunctious, france, ...</small> </th>
                        <th> <small>weary, passionate, reserved, reflection, contemporary folk, delicate, banjo, somber, earthy, autumnal, rustic, intimate, folk, acoustic, ...</small> </th>
                    </tr>
                    <tr> 
                        <th> Contrastive-BERT-Sentence </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/caption/banjo.mp3" type="audio/mpeg"></audio> </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/caption/banjo (1).mp3" type="audio/mpeg"></audio> </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/caption/banjo (2).mp3" type="audio/mpeg"></audio> </th>
                    </tr>
                    <tr> 
                        <th> </th>
                        <th> <small>folk, country</small> </th>
                        <th> <small>folk</small> </th>
                        <th> <small>international, klezmer, jewish music, freewheeling, fun, dramatic, folk, acoustic</small> </th>
                    </tr>
                    <tr> 
                        <th> Contrastive-BERT-Stochastic </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/stochastic/banjo.mp3" type="audio/mpeg"></audio> </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/stochastic/banjo (1).mp3" type="audio/mpeg"></audio> </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/stochastic/banjo (2).mp3" type="audio/mpeg"></audio> </th>
                    </tr>
                    <tr> 
                        <th> </th>
                        <th> <small>contemporary folk, delicate, gentle, drinking, light, cathartic, banjo, somber, earthy, the great outdoors, soothing, comfort, ....</small> </th>
                        <th> <small>maverick, searching, passionate, reserved, reflection, contemporary folk, autumnal, rustic, intimate, folk, autumn, acoustic, ...</small> </th>
                        <th> <small>romantic evening, blues, warm, dramatic, rousing, bright, bravado, yearning, passionate, confident, gutsy, relaxed, sweet, earnest, ...</small> </th>
                    </tr>
                </table>
                <hr/>

                <p><b>Music for meditation or listen to in the forest</b> (Unseen Query)</p>
                <table>
                    <tr>
                        <th> Model </th>
                        <th> Similar Music 1 </th>
                        <th> Similar Music 2 </th>
                        <th> Similar Music 3 </th>
                    </tr>
                    <tr> 
                        <th> Contrastive-BERT-Tag </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/tag/zs.mp3" type="audio/mpeg"></audio> </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/tag/zs (1).mp3" type="audio/mpeg"></audio> </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/tag/zs (2).mp3" type="audio/mpeg"></audio> </th>
                    </tr>
                    <tr> 
                        <th> </th>
                        <th> <small>classical, folk</small> </th>
                        <th> <small>pop rock, beautiful, stagenscreen</small> </th>
                        <th> <small>pop rock, melancholy, dark, psychedelic</small> </th>
                    </tr>
                    <tr> 
                        <th> Contrastive-BERT-Sentence </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/caption/zs.mp3" type="audio/mpeg"></audio> </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/caption/zs (1).mp3" type="audio/mpeg"></audio> </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/caption/zs (2).mp3" type="audio/mpeg"></audio> </th>
                    </tr>
                    <tr> 
                        <th> </th>
                        <th> <small>ambient</small> </th>
                        <th> <small>yearning, intense, passionate, experimental rock, whimsical, cathartic, indie pop, wistful, ambient, summery, the creative side, post rock, ...</small> </th>
                        <th> <small>indie, folk, rock</small> </th>
                    </tr>
                    <tr> 
                        <th> Contrastive-BERT-Stochastic </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/stochastic/zs.mp3" type="audio/mpeg"></audio> </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/stochastic/zs (1).mp3" type="audio/mpeg"></audio> </th>
                        <th> <audio controls id="player" onplay="pauseOthers(this);"><source src="assets/audios/stochastic/zs (2).mp3" type="audio/mpeg"></audio> </th>
                    </tr>
                    <tr> 
                        <th> </th>
                        <th> <small>pop rock, beautiful, indie</small> </th>
                        <th> <small>pop rock, electronic, darkwave, ethereal</small> </th>
                        <th> <small>traditional folk, earnest, literate, intimate, reflective, folk, plaintive, country</small> </th>
                    </tr>
                </table>
                <hr/>

            
            <h4>Abstract</h4>
            <p>This paper introduces effective design choices of unified multimodal representation learning for text-to-music retrieval. We propose a benchmark that includes ten downstream tasks, carefully review existing approaches through a holistic evaluation, then summarize our findings to deliver reusable insights. We found that tag-level and sentence-level text representations are helpful for single-query and multi-query music retrieval, respectively. Thus we leverage both advantages by using a stochastic sampling method. Also, we found that contrastive-based models show more robust performance for unseen query retrieval and probing tasks. Based on these findings, the proposed approach achieves state-of-the-art performance across different music semantic understanding tasks.
            </p>
        
        
            
            <h4>What is stochastic text representations?</h4>
            <p>
            From our empirical study, we find that there is a strong association between text representation (train stage) and text query types (test stage). 
            As somewhat obviously, the model works better when the input forms during the training phase and test phase are homogeneous, there are no references studying the relationship between text representation and retrieval performance. 
            To use the advantages of both, we propose a stochastic text representation. During the training stage, we select <strong>K</strong> words from <strong>L</strong> length text sentence. At this time, <strong>K</strong> is uniformly randomly sampled among integer numbers from <strong>1</strong> (tag length) to <strong>L</strong> (sentence length). Unlike the dropout method, which determines the length by probability value, stochastic sampling has a dynamic input length.
            </p>
            <img class="blog_contents" src="assets/img/sampler.png" alt="framework"/> 

            <h4>What is contrastive loss?</h4>
            <p>
            The core idea of contrastive-based models is to reduce the distance between positive sample pairs while increasing the distance between negative sample pairs. 
            Unlike triplet-based models, contrastive-based models can utilize a large number of negative samples that exist in a mini batch <strong>N</strong>. 
            During training, the audio and text encoders are jointly trained to maximize the similarity between <strong>N</strong> positive pairs of (music, text) associations while minimizing the similarity for negative pairs. 
            This is known as multi-modal version of InfoNCE loss.
            </p>

            <img class="blog_contents" src="assets/img/framework.png" alt="framework"/> 

            <h4>Differences from other loss function </h4>
            <p>
            We explain the contrastive loss, classification loss, and triplet loss from the viewpoint of representation learning. Text-music representation learning aims to learn each encoder based on the similarity of audio embeddings and text embeddings. 
            In this case, the classification loss uses a randomly initialized centroid embedding without a text encoder.
            The classification based model uses the similarity between audio embeddings and centroid embeddings as a prediction score. 
            The prediction of annotated pair becomes a positive score (maximize), and prediction of un-annotated pair becomes negative score (minimize).
            However, the predefined centroid vector of classification is not suitable to cover the language, and updating all parameters at every moment is challenging.
            </p>
            <p>
            On the other hand, triplet loss and contrastive loss do not use a fixed class centroid. Because positive and negative are sampled within a batch, learning is possible even if the vocabulary is large enough. Also, in the case of contrastive loss, all examples in the batch except for self are used as negative. This becomes an extreme classification case when the batch size is large enough.
            </p>
            <img class="blog_contents" src="assets/img/loss_diff.png" alt="framework"/> 

            <h4>Results</h4>
            <p>
            Table show the tag and sentence-based retrieval results. The stochastic representation model achieves competitive results in both tasks. In sentence-based retrieval, it outperforms the sentence representation model, but in tag-based retrieval, it performs closely to the tag representation model. This is because the dynamic length text representation encompasses both tag and sentence embedding space. See our paper for more results on different benchmarks, including MTAT, MTG-Jamendo, FMA, GTZAN, Emotify, KVT.
            </p>
            <img class="blog_contents" src="assets/img/table.png" alt="table"/> 

            <h4>Visualization</h4>
            <img src="assets/img/viz.png" width="50%" style="float: right;"/>
            <p>
                MultiModal embedding spaces are projected to a 2D space using uniform manifold approximation and projection (UMAP). We fit UMAP with music, tag, sentence embeddings, then projected all embeddings into the 2D space. For each dataset, 1000 tag-caption pairs and 1054 tags used for evaluation were used.
                The first row uses a triplet framework with GloVe model. The second row uses a same triplet framework. with BERT model The last row uses a contrastive framework with BERT model. The contrastive model shows a more significant semantic gap than the other models. However, compared with the above results, it is difficult to see the relationship between the semantic gap and performance. Compared with the triplet, the stochastic model shows a smaller semantic gap than other tag and sentence models, and we interpret that each modality is mixed up. In the second column, the sentence-based model, the interesting part is that tag embeddings are isolated. This supports the example in the table above where sentence models showed low performance in tag-based retrieval. Contrary to this, sentence and tag are mixed up in tag-based model. However, since tags are a component of sentence embedding, we do not assume that the model captures the relationship between the two.
            </p>
            <h4>Conclusion</h4>
            <p>In this paper, we introduce effective design choices of generalizable multimodal representation learning for text-to-music retrieval. For the first time, we reveal relationship between text representation and retrieval performance through systematic experiments. Based on the finding, we propose efficient stochastic text representation. The proposed stochastic text representation show robust performance in tag-based, sentence-based, and zero-shot query retrieval cases and state-of-the-art performance on three datasets.
            </p>
        </main>
        <div class="footer"></div>
            </div>
    </body>
</html>
